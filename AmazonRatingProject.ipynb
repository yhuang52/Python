{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ravan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ravan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ravan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pyspark\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenize reviews into words remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_sentences(x, tokenizer, stop_words):\n",
    "    return [word.lower() for word in tokenizer.tokenize(x) if word.lower() not in stop_words and len(word) >=2]\n",
    "\n",
    "raw_data = pd.read_csv(\"../amazon-product-ratings/product_rating.csv\", index_col=0).dropna()\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# tokenize documents into sentences\n",
    "my_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# data['reviews'] = data['reviews'].apply(lambda x: tokenize_sentences(x, my_tokenizer, stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_tagged = [TaggedDocument(review, [i]) for i, review in enumerate(raw_data['reviews'])]\n",
    "train_corpus, test_corpus, y_train, y_test = train_test_split(reviews_tagged, raw_data['ratings'].values, test_size=0.33, random_state=42)\n",
    "# test_corpus = [x.words for x in test_corpus] # we only want words for test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(vector_size=100, min_count=1, epochs=40)\n",
    "model.build_vocab(reviews_tagged)\n",
    "model.train(reviews_tagged, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Train a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.under_sampling  import  RandomUnderSampler\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tags = [x.tags for x in train_corpus]\n",
    "test_tags = [x.tags for x in test_corpus]\n",
    "\n",
    "X_train = model[train_tags]\n",
    "X_test = model[test_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = RandomUnderSampler()\n",
    "X_train_res, y_train_res = sampler.fit_resample(X_train, y)\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = RandomUnderSampler()\n",
    "X_train_res, y_train_res = sampler.fit_resample(X_train, y)\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report_imbalanced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-24981e491b01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report_imbalanced\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report_imbalanced' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report_imbalanced(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../amazon-product-ratings/positive-words.txt\") as f1:\n",
    "    pos_words = f1.read().split('\\n')\n",
    "pos_words = pos_words[:-1]\n",
    "\n",
    "with open(\"../amazon-product-ratings/negative-words.txt\") as f2:\n",
    "    neg_words = f2.read().split('\\n')\n",
    "neg_words = neg_words[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Spark count sentimental words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "rdd = sc.parallelize(raw_data['reviews'].dropna().values)\n",
    "pos_words_count = rdd.map(lambda x: sum([1 for word in x.split(' ') if word in pos_words])).collect()\n",
    "neg_words_count = rdd.map(lambda x: sum([1 for word in x.split(' ') if word in neg_words])).collect()\n",
    "\n",
    "raw_data['pos_words_count'] = pos_words_count\n",
    "raw_data['neg_words_count'] = neg_words_count\n",
    "raw_data['review_length'] = raw_data['reviews'].apply(lambda x: len(my_tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Visulization\n",
    "## We discvoer that in the reviews, sentiment words are highly correlated with the ratings\n",
    "\n",
    "more negative words, means lower the ratings\n",
    "more positive words, mean higher the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e666aece10>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAFpCAYAAAC/CnOrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2bOwSJKk7FlYJElS9iwskiQpe/8flx8sERQKfWIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e66989b978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "raw_data.groupby('ratings').agg({'pos_words_count': 'mean',\n",
    "                                'neg_words_count': 'mean'}).plot(kind='barh', figsize=(9, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# negation in the sentences should be taken care of!\n",
    "\n",
    "\"My little man got this for his first birthday along with the base. Now at 18 months he drags it back into the family room if we move it.  He loves his pony and will climb on and off all on his own whenever the mood strikes him. The base does make it very stable for younger kids and has not once tipped over. I have only had to add more air once to get the pressure back up, **not ** bad considering he has used it daily for half a year. We have the green with blue saddle and colors online are very true (assuming your monitor is).Rody has survived many a chomp on the ears and tail during rough teething times, but between us catching our little culprit and the thickness of the rubber it has not sustained any damage. Rody continues to look overjoyed to see our Son regardless of the abuse and I'm sure will be part of the family for a long time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drags', 'bad', 'rough', 'culprit', 'damage', 'abuse']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in my_tokenizer.tokenize(raw_data.loc[8781]['reviews']) if word in neg_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews length\n",
    "\n",
    "It's reasonable to say, people tend to give longer reviews when they are angry or really hate the product, and tend to give shorter reviews when they are satisifed with the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cb70302d1dd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ratings'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreview_length\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"review length\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn\n",
    "raw_data.groupby('ratings').review_length.median().plot()\n",
    "plt.legend([\"review length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a simple model based on sentimental words count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2493fd511815>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pos_words_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'neg_words_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'review_length'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ratings'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pos_words_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'neg_words_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'review_length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ratings'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw_data' is not defined"
     ]
    }
   ],
   "source": [
    "features_data = raw_data[['pos_words_count', 'neg_words_count', 'review_length', 'ratings']]\n",
    "X = features_data[['pos_words_count', 'neg_words_count', 'review_length']]\n",
    "y = features_data['ratings']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "\n",
    "sampler = SMOTE(k_neighbors=4)\n",
    "X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
    "clf = AdaBoostClassifier(n_estimators=200)\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "mean_absolute_error(clf.predict(X_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('smote', sampler),\n",
    "                     ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.14416189, -1.15292081, -1.1032208 , -1.11260038, -1.06489746])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.14768386, -1.07531118, -1.05841617, -1.01677662, -1.02432908])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45212     0.0\n",
       "104845    0.0\n",
       "88975     1.0\n",
       "8781     -3.0\n",
       "129370   -2.0\n",
       "83703    -2.0\n",
       "33370     0.0\n",
       "77370     0.0\n",
       "78206    -1.0\n",
       "46873    -4.0\n",
       "90828     0.0\n",
       "43145     1.0\n",
       "118269    0.0\n",
       "41516    -4.0\n",
       "148319    0.0\n",
       "26391     0.0\n",
       "9218      0.0\n",
       "79790     0.0\n",
       "113117   -2.0\n",
       "31774     0.0\n",
       "136258   -4.0\n",
       "137098   -2.0\n",
       "114855   -1.0\n",
       "43909     0.0\n",
       "41705     0.0\n",
       "9519      2.0\n",
       "134442   -2.0\n",
       "50576    -2.0\n",
       "124866    1.0\n",
       "104959    0.0\n",
       "         ... \n",
       "136494   -1.0\n",
       "98318     1.0\n",
       "158929   -1.0\n",
       "122895    0.0\n",
       "55479    -1.0\n",
       "34164     0.0\n",
       "2405     -1.0\n",
       "74422     0.0\n",
       "129437    0.0\n",
       "128391    0.0\n",
       "149705    0.0\n",
       "46460    -1.0\n",
       "166229    3.0\n",
       "123040    2.0\n",
       "28034    -2.0\n",
       "26180     1.0\n",
       "119760    0.0\n",
       "33782     2.0\n",
       "55464     0.0\n",
       "53198     0.0\n",
       "71811    -1.0\n",
       "41896     0.0\n",
       "44186     0.0\n",
       "52290    -1.0\n",
       "86134    -1.0\n",
       "391      -2.0\n",
       "90394    -1.0\n",
       "70076    -3.0\n",
       "52890     0.0\n",
       "161040   -1.0\n",
       "Name: ratings, dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_val) - y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
